{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing (Assignement 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division  \n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib import urlopen \n",
    "import requests\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case nltk library is not installed, you have to uncomment the command above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Save the url address of the web page given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://en.wikipedia.org/wiki/Artificial_neural_network\")\n",
    "page.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the metadata of the url as a text and create a BeautifulSoup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html_page = page.text\n",
    "soup = BeautifulSoup(html_page, 'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function which removes all the punctuations from the text and tokenize the words of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text = re.sub(r\"(\\-)\",\" \", text)\n",
    "    words = word_tokenize(text)\n",
    "    return [w.rstrip( string.punctuation) for w in words ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove all the tags (css, javascript,...) except of the html tags which have been already removed by BeautifulSoup , we make all letters lower_case and also call the remove_punct in order to clear the words from numbers and at the same time to tokenize the remaining words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.extract() for x in soup.find_all('script')]\n",
    "[x.extract() for x in soup.find_all('mstyle')]\n",
    "[x.extract() for x in soup.find_all('img')]\n",
    "[x.extract() for x in soup.find_all('span')]\n",
    "text = soup.get_text().lower()\n",
    "Letter = re.compile('.*[a-z].*')\n",
    "new_text = remove_punct(text)\n",
    "new_text = [i for i in new_text if i!=\"\"]\n",
    "clear_text = [i for i in new_text if Letter.match(i)]\n",
    "clear_text \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_length = len(clear_text )\n",
    "print total_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find how many times each word exist in the document (Vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(clear_text)\n",
    "print counts\n",
    "#print len(counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of sentences in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = len(re.findall(\"(\\.)\", text))\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find lexical diversity (ratio of the number of unique words to the total number of the words of the uncleaned text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity = float(len(set(text)) / len(text))\n",
    "print diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the 5 most common lexical categories in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = nltk.pos_tag(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for (i,j) in tags:\n",
    "    lst.append(j)\n",
    "nltk.FreqDist(lst).most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all the stopWords using nltk.corpus.stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = [word for word in new_text if word not in stopwords.words('english')]\n",
    "filtered_words2 = [word for word in filtered_words if len(word) > 2]\n",
    "filtered_words2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 most common unigrams and 10 most common bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams2 = ngrams(filtered_words2 , 1)\n",
    "Counter(ngrams2).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams2 = ngrams(filtered_words2 , 2)\n",
    "Counter(ngrams2).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of nouns in the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst2 = [\"NN\", \"NNS\", \"NNP\", \"NNPS\"]\n",
    "lst3 = []\n",
    "for (i,j) in tags:\n",
    "    if j in lst2:\n",
    "        lst3.append(i)\n",
    "lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lst3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second part of this exercise we have to create a csv file with 3 cells which contain name, surname and a string. The file will be created with the following code. Finally the file can be clicked and be opened by default with microsoft excel if the host is Windows 10, or libre-office in case of Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodecsv as csv\n",
    "with open('output.csv', 'wb') as f:\n",
    "    f.write(u'\\ufeff'.encode('utf8'))\n",
    "    f.write(\"name;firstname;\\\"\\\"\\\"MSc in Data Science\\\"\\\"\\\"\")\n",
    "    writer = csv.writer(f, delimiter=';', lineterminator='\\n', dialect='excel', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
